{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e76b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import os, requests, pandas as pd, pathlib, datetime as dt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb568077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()           \n",
    "\n",
    "import os\n",
    "TOKEN  = os.getenv(\"EVENTBRITE_PRIVATE\")   \n",
    "BASE    = \"https://www.eventbriteapi.com/v3\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "assert TOKEN, \"–î–æ–±–∞–≤—å—Ç–µ EVENTBRITE_PRIVATE –≤ .env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cda92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "YEAR_START = 2019\n",
    "YEAR_END   = 2024\n",
    "STATUS     = \"ended\"        # –º–æ–∂–Ω–æ 'live', 'draft', 'started', 'all'\n",
    "PAGE_SIZE  = 200             # –º–∞–∫—Å 200\n",
    "SLEEP      = 0.1             # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å API\n",
    "\n",
    "# ----------------------------- 3.   –§–£–ù–ö–¶–ò–ò --------------------------\n",
    "\n",
    "def list_my_orgs() -> list[str]:\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ org_id, –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–∫—É—â–µ–º—É —Ç–æ–∫–µ–Ω—É.\"\"\"\n",
    "    url      = f\"{BASE}/users/me/organizations/\"\n",
    "    org_ids  = []\n",
    "    params   = {\"page_size\": PAGE_SIZE}\n",
    "    while True:\n",
    "        resp = requests.get(url, headers=HEADERS, params=params)\n",
    "        resp.raise_for_status()\n",
    "        pj = resp.json()\n",
    "        org_ids.extend(org[\"id\"] for org in pj[\"organizations\"])\n",
    "        if not pj[\"pagination\"][\"has_more_items\"]:\n",
    "            break\n",
    "        params = {\"continuation\": pj[\"pagination\"][\"continuation\"]}\n",
    "    return org_ids\n",
    "\n",
    "\n",
    "def fetch_events_brief(org_id: str) -> list[dict]:\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä–æ –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–±–µ–∑ venue).\"\"\"\n",
    "    params = {\n",
    "        \"status\": STATUS,\n",
    "        \"page_size\": PAGE_SIZE,\n",
    "        \"start_date.range_start\": f\"{YEAR_START}-01-01T00:00:00Z\",\n",
    "        # upper bound –Ω–µ–ª—å–∑—è ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ—Ç–æ–º\n",
    "    }\n",
    "    url   = f\"{BASE}/organizations/{org_id}/events/\"\n",
    "    items = []\n",
    "    while True:\n",
    "        r = requests.get(url, headers=HEADERS, params=params)\n",
    "        r.raise_for_status()\n",
    "        pj = r.json()\n",
    "        items.extend(pj[\"events\"])\n",
    "        if not pj[\"pagination\"][\"has_more_items\"]:\n",
    "            break\n",
    "        params = {\"continuation\": pj[\"pagination\"][\"continuation\"]}\n",
    "        time.sleep(SLEEP)\n",
    "    return items\n",
    "\n",
    "\n",
    "def enrich_event(event_id: str) -> dict:\n",
    "    \"\"\"–î–æ—Å—Ç–∞—ë—Ç –ø–æ–ª–Ω—ã–π JSON —Å–æ–±—ã—Ç–∏—è —Å expand=venue.\"\"\"\n",
    "    url = f\"{BASE}/events/{event_id}/?expand=venue\"\n",
    "    r   = requests.get(url, headers=HEADERS)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def normalize(events_raw: list[dict]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for ev in events_raw:\n",
    "        venue = ev.get(\"venue\", {})\n",
    "        addr  = venue.get(\"address\", {})\n",
    "        start = ev[\"start\"][\"utc\"]\n",
    "        if start < f\"{YEAR_START}-01-01T00:00:00Z\" or start > f\"{YEAR_END}-12-31T23:59:59Z\":\n",
    "            continue  # —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤–µ—Ä—Ö–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É –∏ –ª–∏—à–Ω–∏–µ —Å—Ç–∞—Ç—É—Å—ã\n",
    "        rows.append({\n",
    "            \"event_id\":  ev[\"id\"],\n",
    "            \"org_id\":    ev[\"organization_id\"],\n",
    "            \"name\":      ev[\"name\"][\"text\"],\n",
    "            \"start_utc\": start,\n",
    "            \"end_utc\":   ev[\"end\"][\"utc\"],\n",
    "            \"status\":    ev.get(\"status\"),\n",
    "            \"category\":  ev.get(\"category_id\"),\n",
    "            \"capacity\":  ev.get(\"capacity\"),\n",
    "            \"venue_id\":  venue.get(\"id\"),\n",
    "            \"lat\":       addr.get(\"latitude\"),\n",
    "            \"lon\":       addr.get(\"longitude\"),\n",
    "            \"address\":   addr.get(\"localized_address_display\"),\n",
    "            \"wkt\": (f\"POINT({addr.get('longitude')} {addr.get('latitude')})\"\n",
    "                     if addr.get(\"latitude\") and addr.get(\"longitude\") else None)\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"start_utc\"] = pd.to_datetime(df[\"start_utc\"])\n",
    "        df[\"end_utc\"]   = pd.to_datetime(df[\"end_utc\"])\n",
    "        df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "        df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------- 4.   MAIN ------------------------------\n",
    "\n",
    "def main():\n",
    "    org_ids = list_my_orgs()\n",
    "    if not org_ids:\n",
    "        raise SystemExit(\"–£ —Ç–æ–∫–µ–Ω–∞ –Ω–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π. –°–æ–∑–¥–∞–π—Ç–µ —á–µ—Ä–Ω–æ–≤–∏–∫ –∏–ª–∏ –∑–∞–ø—Ä–æ—Å–∏—Ç–µ OAuth-–¥–æ—Å—Ç—É–ø.\")\n",
    "\n",
    "    print(\"–ù–∞–π–¥–µ–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π:\", len(org_ids), \"‚Üí\", \", \".join(org_ids))\n",
    "\n",
    "    enriched_events: list[dict] = []\n",
    "\n",
    "    for org in tqdm(org_ids, desc=\"–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\"):\n",
    "        brief_events = fetch_events_brief(org)\n",
    "        if not brief_events:\n",
    "            print(f\"‚ö†Ô∏è  –í –æ—Ä–≥ {org} –Ω–µ—Ç —Å–æ–±—ã—Ç–∏–π –ø–æ–¥ —Å—Ç–∞—Ç—É—Å–æ–º '{STATUS}' –∏ –¥–∞—Ç–∞–º–∏ >= {YEAR_START}\")\n",
    "            continue\n",
    "        for ev in tqdm(brief_events, desc=f\"  events {org}\", leave=False):\n",
    "            try:\n",
    "                enriched = enrich_event(ev[\"id\"])\n",
    "                enriched_events.append(enriched)\n",
    "            except requests.HTTPError as e:\n",
    "                print(\"üö´\", ev[\"id\"], e)\n",
    "            time.sleep(SLEEP)\n",
    "\n",
    "    if not enriched_events:\n",
    "        raise SystemExit(\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–±—ã—Ç–∏–π.\")\n",
    "\n",
    "    df = normalize(enriched_events)\n",
    "    print(\"‚úÖ –°–æ–±—ã—Ç–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞:\", len(df))\n",
    "\n",
    "    outdir = pathlib.Path(\"eventbrite_exports\")\n",
    "    outdir.mkdir(exist_ok=True)\n",
    "    outfile = outdir / f\"events_all_{dt.datetime.utcnow():%Y%m%d}.csv\"\n",
    "    df.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    from IPython.display import display  # Jupyter preview\n",
    "    display(df.head())\n",
    "    print(\"üìÑ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω:\", outfile.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8f1b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "‚ö†Ô∏è  –í .env –Ω–µ—Ç EVENTBRITE_PRIVATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m load_dotenv()\n\u001b[32m     26\u001b[39m TOKEN = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mEVENTBRITE_PRIVATE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m TOKEN, \u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è  –í .env –Ω–µ—Ç EVENTBRITE_PRIVATE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m BASE    = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.eventbriteapi.com/v3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m HEADERS = {\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOKEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}\n",
      "\u001b[31mAssertionError\u001b[39m: ‚ö†Ô∏è  –í .env –Ω–µ—Ç EVENTBRITE_PRIVATE"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"eventbrite_export_full.py\n",
    "\n",
    "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è Jupyter / Python 3.x\n",
    "-------------------------------------------\n",
    "* –ë–µ—Ä—ë—Ç PRIVATE‚Äë—Ç–æ–∫–µ–Ω –∏–∑ .env (EVENTBRITE_PRIVATE)\n",
    "* –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –∫ –∫–æ—Ç–æ—Ä—ã–º —Ç–æ–∫–µ–Ω –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø\n",
    "* –í—ã–≥—Ä—É–∂–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è (ended/live/draft ‚Äî –∑–∞–¥–∞—ë—Ç—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º) –∑–∞ –¥–∏–∞–ø–∞–∑–æ–Ω –ª–µ—Ç\n",
    "* –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–±—ã—Ç–∏—è –¥–µ–ª–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å expand=venue, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å lat/lon\n",
    "* –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ CSV + –≤—ã–≤–æ–¥–∏—Ç –ø—Ä–µ–≤—å—é DataFrame\n",
    "\n",
    "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (pip install): requests pandas python-dotenv tqdm\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------- 1. –ò–ú–ü–û–†–¢–´ -----------------------------\n",
    "from __future__ import annotations\n",
    "import os, pathlib, datetime as dt, time\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ----------------------------- 2.   –ù–ê–°–¢–†–û–ô–ö–ò ------------------------\n",
    "load_dotenv()\n",
    "TOKEN = os.getenv(\"EVENTBRITE_PRIVATE\")\n",
    "assert TOKEN, \"‚ö†Ô∏è  –í .env –Ω–µ—Ç EVENTBRITE_PRIVATE\"\n",
    "\n",
    "BASE    = \"https://www.eventbriteapi.com/v3\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "\n",
    "YEAR_START = 2019\n",
    "YEAR_END   = 2024\n",
    "STATUS     = \"ended\"        # –º–æ–∂–Ω–æ 'live', 'draft', 'started', 'all'\n",
    "PAGE_SIZE  = 200             # –º–∞–∫—Å 200\n",
    "SLEEP      = 0.1             # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å API\n",
    "\n",
    "# ----------------------------- 3.   –§–£–ù–ö–¶–ò–ò --------------------------\n",
    "\n",
    "def list_my_orgs() -> list[str]:\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ org_id, –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–∫—É—â–µ–º—É —Ç–æ–∫–µ–Ω—É.\"\"\"\n",
    "    url      = f\"{BASE}/users/me/organizations/\"\n",
    "    org_ids  = []\n",
    "    params   = {\"page_size\": PAGE_SIZE}\n",
    "    while True:\n",
    "        resp = requests.get(url, headers=HEADERS, params=params)\n",
    "        resp.raise_for_status()\n",
    "        pj = resp.json()\n",
    "        org_ids.extend(org[\"id\"] for org in pj[\"organizations\"])\n",
    "        if not pj[\"pagination\"][\"has_more_items\"]:\n",
    "            break\n",
    "        params = {\"continuation\": pj[\"pagination\"][\"continuation\"]}\n",
    "    return org_ids\n",
    "\n",
    "\n",
    "def fetch_events_brief(org_id: str) -> list[dict]:\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä–æ –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–±–µ–∑ venue).\"\"\"\n",
    "    params = {\n",
    "        \"status\": STATUS,\n",
    "        \"page_size\": PAGE_SIZE,\n",
    "        \"start_date.range_start\": f\"{YEAR_START}-01-01T00:00:00Z\",\n",
    "        # upper bound –Ω–µ–ª—å–∑—è ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ—Ç–æ–º\n",
    "    }\n",
    "    url   = f\"{BASE}/organizations/{org_id}/events/\"\n",
    "    items = []\n",
    "    while True:\n",
    "        r = requests.get(url, headers=HEADERS, params=params)\n",
    "        r.raise_for_status()\n",
    "        pj = r.json()\n",
    "        items.extend(pj[\"events\"])\n",
    "        if not pj[\"pagination\"][\"has_more_items\"]:\n",
    "            break\n",
    "        params = {\"continuation\": pj[\"pagination\"][\"continuation\"]}\n",
    "        time.sleep(SLEEP)\n",
    "    return items\n",
    "\n",
    "\n",
    "def enrich_event(event_id: str) -> dict:\n",
    "    \"\"\"–î–æ—Å—Ç–∞—ë—Ç –ø–æ–ª–Ω—ã–π JSON —Å–æ–±—ã—Ç–∏—è —Å expand=venue.\"\"\"\n",
    "    url = f\"{BASE}/events/{event_id}/?expand=venue\"\n",
    "    r   = requests.get(url, headers=HEADERS)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def normalize(events_raw: list[dict]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for ev in events_raw:\n",
    "        venue = ev.get(\"venue\", {})\n",
    "        addr  = venue.get(\"address\", {})\n",
    "        start = ev[\"start\"][\"utc\"]\n",
    "        if start < f\"{YEAR_START}-01-01T00:00:00Z\" or start > f\"{YEAR_END}-12-31T23:59:59Z\":\n",
    "            continue  # —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤–µ—Ä—Ö–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É –∏ –ª–∏—à–Ω–∏–µ —Å—Ç–∞—Ç—É—Å—ã\n",
    "        rows.append({\n",
    "            \"event_id\":  ev[\"id\"],\n",
    "            \"org_id\":    ev[\"organization_id\"],\n",
    "            \"name\":      ev[\"name\"][\"text\"],\n",
    "            \"start_utc\": start,\n",
    "            \"end_utc\":   ev[\"end\"][\"utc\"],\n",
    "            \"status\":    ev.get(\"status\"),\n",
    "            \"category\":  ev.get(\"category_id\"),\n",
    "            \"capacity\":  ev.get(\"capacity\"),\n",
    "            \"venue_id\":  venue.get(\"id\"),\n",
    "            \"lat\":       addr.get(\"latitude\"),\n",
    "            \"lon\":       addr.get(\"longitude\"),\n",
    "            \"address\":   addr.get(\"localized_address_display\"),\n",
    "            \"wkt\": (f\"POINT({addr.get('longitude')} {addr.get('latitude')})\"\n",
    "                     if addr.get(\"latitude\") and addr.get(\"longitude\") else None)\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"start_utc\"] = pd.to_datetime(df[\"start_utc\"])\n",
    "        df[\"end_utc\"]   = pd.to_datetime(df[\"end_utc\"])\n",
    "        df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "        df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------- 4.   MAIN ------------------------------\n",
    "\n",
    "def main():\n",
    "    org_ids = list_my_orgs()\n",
    "    if not org_ids:\n",
    "        raise SystemExit(\"–£ —Ç–æ–∫–µ–Ω–∞ –Ω–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π. –°–æ–∑–¥–∞–π—Ç–µ —á–µ—Ä–Ω–æ–≤–∏–∫ –∏–ª–∏ –∑–∞–ø—Ä–æ—Å–∏—Ç–µ OAuth-–¥–æ—Å—Ç—É–ø.\")\n",
    "\n",
    "    print(\"–ù–∞–π–¥–µ–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π:\", len(org_ids), \"‚Üí\", \", \".join(org_ids))\n",
    "\n",
    "    enriched_events: list[dict] = []\n",
    "\n",
    "    for org in tqdm(org_ids, desc=\"–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\"):\n",
    "        brief_events = fetch_events_brief(org)\n",
    "        if not brief_events:\n",
    "            print(f\"‚ö†Ô∏è  –í –æ—Ä–≥ {org} –Ω–µ—Ç —Å–æ–±—ã—Ç–∏–π –ø–æ–¥ —Å—Ç–∞—Ç—É—Å–æ–º '{STATUS}' –∏ –¥–∞—Ç–∞–º–∏ >= {YEAR_START}\")\n",
    "            continue\n",
    "        for ev in tqdm(brief_events, desc=f\"  events {org}\", leave=False):\n",
    "            try:\n",
    "                enriched = enrich_event(ev[\"id\"])\n",
    "                enriched_events.append(enriched)\n",
    "            except requests.HTTPError as e:\n",
    "                print(\"üö´\", ev[\"id\"], e)\n",
    "            time.sleep(SLEEP)\n",
    "\n",
    "    if not enriched_events:\n",
    "        raise SystemExit(\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–±—ã—Ç–∏–π.\")\n",
    "\n",
    "    df = normalize(enriched_events)\n",
    "    print(\"‚úÖ –°–æ–±—ã—Ç–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞:\", len(df))\n",
    "\n",
    "    outdir = pathlib.Path(\"eventbrite_exports\")\n",
    "    outdir.mkdir(exist_ok=True)\n",
    "    outfile = outdir / f\"events_all_{dt.datetime.utcnow():%Y%m%d}.csv\"\n",
    "    df.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    from IPython.display import display  # Jupyter preview\n",
    "    display(df.head())\n",
    "    print(\"üìÑ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω:\", outfile.resolve())\n",
    "\n",
    "# ----------------------------- 5.   RUN -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf729127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c14e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb604f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
